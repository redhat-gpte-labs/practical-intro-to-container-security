:GUID: %guid%
:markup-in-source: verbatim,attributes,quotes
:toc:

=== What is a pod?

A pod is a group of one or more containers with shared storage, network and a specification for how to run the containers. In this module you'll be working at the container level. Since you are here to learn more about
container security, we have a quick review of 
container basics then get right into the good stuff. 

Podman (Pod Manager) is a fully featured container engine that is a simple daemon-less tool. Podman provides a Docker-CLI comparable command line experience that eases the transition and allows the management of pods, containers and images. Simply put, `alias docker=podman`. 

Also, most `podman` commands can be run as a regular,
non-root user, without requiring additional privileges. This presents significant security and auditing advantages
over client-server based architectures.

=== The Universal Base Image

The container image that you will be using through out most of this lab is the RHEL 9 Universal Base Image https://access.redhat.com/containers/#/product/5c180b28bed8bd75a2c29a63[(UBI)]. The UBI is designed and engineered to be the base layer for containerized applications, middleware and utilities. This base image is freely distributable. However, Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. When you get a chance, read more about https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html-single/getting_started_with_containers/index#using_red_hat_universal_base_images_standard_minimal_and_runtimes[ using the UBI]. 

.Pull the RHEL 9 UBI image from RedHat's container registry. Do this on the bastion node.
--
[source,subs="{markup-in-source}"]
----
$ *podman pull %RHEL_CONTAINER%*
----
----
Trying to pull %RHEL_CONTAINER%...
Getting image source signatures
...
...
Storing signatures
0c46e5c7a82a97d21447ee6a1ef0d407317642c9361b562456395e087be08774
----
--

.Now do the same as the root user. 
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman pull %RHEL_CONTAINER%*
----
--

The container images for these different users are stored in unique locations. Use the `podman` command to find out where they are stored in the file system.

.Hint
--
[source,subs="{markup-in-source}"]
----
$ *podman inspect %RHEL_CONTAINER% | grep WorkDir*
----
--

Notice that pulling the UBI does not require 
authentication from RedHat's registries.

Next, we'll work with the registries that were configured
in the previous modules.

=== Tagging and pushing images to a remote registry

Before an image can be pushed to a registry, it must be tagged 
appropriately.

.Pull an image from quay.io
--
[source,subs="{markup-in-source}"]
----
$ podman pull quay.io/bkozdemb/hello
----
--

.Confirm the pull worked
--
[source,subs="{markup-in-source}"]
----
$ *podman images*
----
----
REPOSITORY                            TAG      IMAGE ID       CREATED      SIZE
quay.io/bkozdemb/hello                latest  398a3b0bab81  7 months ago   250 MB
----
--

.Next tag the image for the remote registry hosted at node1.{GUID}.internal
--
[source,subs="{markup-in-source}"]
----
$ *podman tag quay.io/bkozdemb/hello node1.{GUID}.internal:5000/mynamespace/hello*
----
--

.Confirm the tag is correct
--
[source,subs="{markup-in-source}"]
----
$ *podman images*
----
[source,subs="{markup-in-source}"]
----
REPOSITORY                            TAG      IMAGE ID       CREATED      SIZE
quay.io/bkozdemb/hello                latest  398a3b0bab81  7 months ago   250 MB
node1.{GUID}.internal:5000/mynamespace/hello  latest  398a3b0bab81  7 months ago
   250 MB
----
--

.Login to the `node1.{GUID}.internal` registry. Do the same for `node2.{GUID}.internal`. 
[source,subs="{markup-in-source}"]
----
$ *podman login -u redhat -p redhat node1.{GUID}.internal:5000*
----
----
Login Succeeded!
----
[source,subs="{markup-in-source}"]
----
$ *podman login -u redhat -p redhat node2.{GUID}.internal:5000*
----
----
Login Succeeded!
----

[IMPORTANT]
.If the following error message is reported
====
[subs="{markup-in-source}"]
----
Error: error authenticating creds for "node1.{GUID}.internal:5000": error pinging docker registry node1.{GUID}.internal:5000: Get "https://node1.{GUID}.internal:5000/v2/": x509: certificate relies on legacy 
Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG=x509ignoreCN=0
----

The `GODEBUG` variable needs to be set.
[source,subs="{markup-in-source}"]
----
$ *export GODEBUG=x509ignoreCN=0*
----
====

.Finally, push the image
--
[source,subs="{markup-in-source}"]
----
$ *podman push node1.{GUID}.internal:5000/mynamespace/hello*
----
----
Getting image source signatures
Copying blob 8da573feae5f: 205.77 MiB / 205.77 MiB [========================] 5s
Copying blob 6ef321d2357f: 10.00 KiB / 10.00 KiB [==========================] 5s
Copying config cc7efd763847: 0 B / 4.36 KiB [-------------------------------] 0s
Writing manifest to image destination
Writing manifest to image destination
Storing signatures
----
--

.Confirm the push succeeded and the repository was created.
--
[source,subs="{markup-in-source}"]
----
$ *curl --user redhat:redhat https://node1.{GUID}.internal:5000/v2/_catalog*
----
----
{"repositories":["hello","mynamespace/hello"]}
----
--

=== Working with root and rootless containers.

Podman supports storing and running root and rootless containers. Effectively, each user manages it's own containers.

The UBI container images should be loaded into the podman's local image storage for both root and rootless (lab-user) usage. 

Confirm these images exist using `podman`. Note the `podman` command may be run as **root** (privileged) or as a **root-less** (non-privileged) user.

.Examine container image storage
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman images*
$ *podman images*
----
----
REPOSITORY                            TAG      IMAGE ID       CREATED       SIZE
%RHEL_CONTAINER%   latest   8121a9f5303b   8 days ago   240 MB
----
--

.Where are the container images actually stored? 
--
It depends on the user. For a rootless user, they are stored in the home directory. 
There are separate directories for images (once they are pulled) and containers
(once they have run).
[source,subs="{markup-in-source}"]
----
$ *ls $HOME/.local/share/containers/storage*
----
----
cache/	libpod/  mounts/  overlay/  overlay-containers/  overlay-images/  overlay-layers/  storage.lock  tmp/  userns.lock
----
--

.Here is an example to locate the storage directory for an image
--
[source,subs="{markup-in-source}"]
----
$ *podman images*
----
----
REPOSITORY                           TAG     IMAGE ID      CREATED        SIZE
quay.io/bkozdemb/hello               latest  398a3b0bab81  7 months ago   250 MB
----
--

.Use the image ID to locate the actual layers
--
[source,subs="{markup-in-source}"]
----
$ *ls -R .local/share/containers | grep 398a3b0bab81*
----
----
398a3b0bab8109a059a2a1cb733553cab01d7350bf439063b3b39b02937c9064/
.local/share/containers/storage/overlay-images/398a3b0bab8109a059a2a1cb733553cab01d7350bf439063b3b39b02937c9064:
----
--

How would you do the same for a running container? You should be able to answer that soon.

.For the root user, image layers are stored in `/run/containers`
--
[source,subs="{markup-in-source}"]
----
$ *sudo ls /run/containers/storage*
----
----
overlay  overlay-containers  overlay-layers  overlay-locks
----
--

Let's start with a few more warmup exercises. Note that a random _container ID_ is returned when the container starts.

.Run a rootless container
[source,subs="{markup-in-source}"]
----
$ *podman run --name=rootless -d %RHEL_CONTAINER% sleep 999*
----
----
815dd74131decfed827b4087785e54b780eef12e44392ff1146c31179b29a855
----

.Examine the running containers
[source,subs="{markup-in-source}"]
----
$ *podman ps*
----
----
CONTAINER ID  IMAGE                                       COMMAND    CREATED         STATUS             PORTS  NAMES
e05c3fc400eb  %RHEL_CONTAINER%:latest  sleep 999  2 seconds ago   Up 2 seconds ago          rootless
----

.Now do the same for a root container
[source,subs="{markup-in-source}"]
----
$ *sudo podman run --name=root -d %RHEL_CONTAINER% sleep 999* 
----
----
815dd74131decfed827b4087785e54b780eef12e44392ff1146c31179b29a855
----
[source,subs="{markup-in-source}"]
----
$ *sudo podman ps*
----
----
CONTAINER ID  IMAGE                       COMMAND    CREATED         STATUS             PORTS  NAMES
493da8f543de  %RHEL_CONTAINER%  sleep 999  43 seconds ago  Up 42 seconds ago         root
----

=== Stopping and removing containers

.With grace
--
[source,subs="{markup-in-source}"]
----
$ *podman stop rootless*
$ *podman rm rootless*

$ *sudo podman stop root*
$ *sudo podman rm root*
----
--

.With brute
--
[source,subs="{markup-in-source}"]
----
$ *podman rm -f rootless*
$ *sudo podman rm -f root*
----
--

=== Container process information

Podman top can be used to display information about the running process of the container. Use it to answer the following.

.What command is run when the container is run?
--
[source,subs="{markup-in-source}"]
----
$ *podman run --name=rootless -d %RHEL_CONTAINER% sleep 999*
----
--

.How long has this container been running?
--
[source,subs="{markup-in-source}"]
----
$ *podman top -l args etime*
----
--

.Clean up
--
[source,subs="{markup-in-source}"]
----
$ *podman rm -f rootless*
----
--

=== User Namespace Support

To observe user namespace support, you will run a rootless container
and observe the UID and PID in both the container and host namespaces.

.Start by running a rootless container in the background
--
[source,subs="{markup-in-source}"]
----
$ *podman run --name sleepy -d %RHEL_CONTAINER% sleep 999*
----
--

Next, run `podman top` to list the processes running in the 
container. Take note of the USER and the PID. The container process is running as
the `lab-user` user even though the container thinks it is `root`. This is 
user namespaces in action. 

.What does the `-l` option do?
--
[source,subs="{markup-in-source}"]
----
$ *podman top -l*
----
--

.Next, on the host, list the same container process and take note of the UID and the PID
--
[source,subs="{markup-in-source}"]
----
$ *ps -ef| grep sleep*

UID        PID  PPID  C STIME TTY          TIME CMD
lab-user  1701  1690  0 07:30 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 999
----
--

Compare those ID's to the same process running in the hosts
namespace.

[TIP]
.Take note of 2 important concepts from this example
====
* The `sleep` process in the container is owned by `root` but
the process on the host is owned by `lab-user`. This is
user namespaces in action. The **fork/exec** model used by podman 
improves the security auditing of containers. It allows an administrator to identify users
that run containers as root. Container engines that
use a ***client/server*** model can't provide this.

* The `sleep` process in the container has a PID of 1 but 
on the host the PID is **rootless** (a PID >1). This is
kernel namespaces in action.
====

.Clean up
--
[source,subs="{markup-in-source}"]
----
$ *podman rm -f sleepy*
----
--

=== Auditing containers

.Take note of the `lab-user` UID
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman run --name sleepy --rm -it %RHEL_CONTAINER% bash -c "cat /proc/self/loginuid;echo"*
----
----
1000
----
--

.Configure the kernel audit system to watch the `/etc/shadow` file
--
[source,subs="{markup-in-source}"]
----
$ *sudo auditctl -w /etc/shadow 2>/dev/null*
----
--

.Run a privileged container that bind mounts the host's file system then touches `/etc/shadow`
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman run --privileged --rm -v /:/host %RHEL_CONTAINER% touch /host/etc/shadow*
----
--

.Examine the kernel audit system log to determine which user ran the malicious privileged container
--
[source,subs="{markup-in-source}"]
----
$ *sudo ausearch -m path -ts recent -i | grep touch | grep --color=auto 'auid=[^ ]*'*
----
----
type=SYSCALL msg=audit(04/30/2019 11:03:03.384:425) : arch=x86_64 syscall=openat success=yes exit=3 a0=0xffffff9c a1=0x7ffeee3ecf5c a2=O_WRONLY|O_CREAT|O_NOCTTY|O_NONBLOCK a3=0x1b6 items=2 ppid=6168 pid=6180 auid=lab-user uid=root gid=root euid=root suid=root fsuid=root egid=root sgid=root fsgid=root tty=(none) ses=11 comm=touch exe=/usr/bin/coreutils subj=unconfined_u:system_r:spc_t:s0 key=(null) 
----
--

TIP: Try this at home using another container engine based on a client/server model and you 
will notice that the offending audit ID is reported as `4294967295` (i.e. an `unsignedint(-1)`).
In other words, the malicious user is unknown.  

=== UID Mapping

A container administrator can make use *podman's* `--uidmap` option to force a range of UID's to be used. See
`podman-run(1)` for details.

.Run a container that maps `5000` UIDs starting at `100,000`. This example maps uids `0-5000` in the container to the uids `100,000 - 104,999` on the host
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman run --uidmap 0:100000:5000 -d %RHEL_CONTAINER% sleep 1000*
----
----
98554ea68dae250deeaf78d9b20069716e40eeaf1804b070eb408c9894b1df5a
----
--

.Check the container
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman top --latest user huser | grep --color=auto -B 1 100000*
----
----
USER   HUSER
root   100000
----
--

.Check the host
--
[source,subs="{markup-in-source}"]
----
$ *ps -f --user=100000*
----
----
UID        PID  PPID  C STIME TTY          TIME CMD
100000    2894  2883  0 12:40 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 1000
----
--

.Do the same beginning at uid `200,000`
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman run --uidmap 0:200000:5000 -d %RHEL_CONTAINER% sleep 1000*
----
----
0da91645b9c5e4d77f16f7834081811543f5d2c5e2a510e3092269cbd536d978
----
--

.Check the container
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman top --latest user huser | grep --color=auto -B 1 200000*
----
----
USER   HUSER
root   200000
----
--

.Check the host
--
[source,subs="{markup-in-source}"]
----
$ *ps -f --user=200000*
----
----
UID        PID  PPID  C STIME TTY          TIME CMD
200000    3024  3011  0 12:41 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 1000
----
--

=== Challenge

The `--user` argument can be used to tell `podman` to use a specific effective user in the container namespace. In other words, repeat the previous example specifying the user to be `1001` which is `%USERNAME%`.This can be confirmed by examining the `/etc/passwd` file.

.The `top` results should look like:
--
[source,subs="{markup-in-source}"]
----
$ *sudo podman top -l user huser*
----
----
USER   HUSER
1001   201001
----
--

.Solution
[%collapsible]
====
[source,subs="{markup-in-source}"]
----
$ *sudo podman run --name=mytest --user=1001 --uidmap 0:200000:5000 -d registry.access.redhat.com/ubi8/ubi:8.1 sleep 1000*
----
====

=== Clean up challenge

Use `podman` to stop and remove any containers before proceeding with the next lab.

.The result should look like:
--
[source,subs="{markup-in-source}"]
----
$ podman ps -a
----
----
CONTAINER ID  IMAGE       COMMAND     CREATED     STATUS      PORTS       NAMES
----
--

.Solution
[%collapsible]
====
[source,subs="{markup-in-source}"]
----
$ *for i in $(sudo podman ps -a -q); do sudo podman stop $i && sudo podman rm $i; done*
----
====

=== References

https://kubernetes.io/docs/concepts/workloads/pods/pod/[Pod concepts]

https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/building_running_and_managing_containers/index[podman user guide]
